# ==============================================================================
# Veridis Decentralized Identity Protocol - Development Testing Configuration Patch
# ==============================================================================
#
# This Development Testing Configuration Patch provides comprehensive development-optimized
# testing configuration for the Veridis Decentralized Identity Protocol, providing:
#
# ENTERPRISE VERIDIS DEVELOPMENT TESTING ARCHITECTURE:
#   • Advanced Development Testing with intelligent testing management and comprehensive development-based optimization
#   • Multi-tier Development Testing architecture with unit testing, integration testing, E2E testing, and validation environments
#   • Comprehensive development testing framework with Testing policies, developer tooling integration, testing automation
#   • Advanced lifecycle management with automated Testing optimization, developer control, and development enhancement
#   • Enterprise-grade development intelligence with comprehensive analytics and Development Testing performance insights
#
# VERIDIS DEVELOPMENT TESTING OPTIMIZATION:
#   • High-performance Development with intelligent testing management and developer-optimized testing allocation
#   • Intelligent Development testing management with responsive policies and development-based testing decisions
#   • Advanced Development management with business intelligence and testing-based developer control
#   • Comprehensive development testing control with intelligent Developer Testing management and testing enhancement
#   • Enterprise acceleration with predictive Developer Testing management and development testing optimization
#
# COMPLIANCE FRAMEWORK INTEGRATION:
#   • SOC 2 Type II Development Testing controls with comprehensive audit and development requirements
#   • GDPR Development Testing compliance with data protection, privacy controls, and development management
#   • ISO 27001 Development Testing management with comprehensive framework integration
#   • NIST 800-190 container Development Testing security with development-specific validation and compliance
#   • Zero-knowledge protocol compliance with regulatory frameworks and Development Testing best practices
#
# ENTERPRISE OPERATIONAL EXCELLENCE:
#   • Intelligent Development Testing lifecycle management with automated provisioning and development optimization
#   • Predictive development analytics with capacity planning and Development Testing intelligence
#   • Advanced Testing integration with Developer development analytics and performance business intelligence
#   • Comprehensive development testing control with Development Testing preservation and testing optimization
#   • Business continuity Development Testing with development guarantees and performance optimization
#
# DEVELOPMENT TESTING ACCELERATION INTELLIGENCE:
#   • Development Testing usage analytics with development patterns and optimization recommendations
#   • Testing monitoring with Developer development latency and management optimization intelligence
#   • Development efficiency with Development Testing analytics and deployment optimization procedures
#   • Cost optimization with Development Testing utilization analysis and development capacity planning procedures
#   • Quality assurance with Development Testing metrics and development validation procedures
#
# ==============================================================================

# ==============================================================================
# Development Testing Environment Configuration Patch
# ==============================================================================
apiVersion: apps/v1
kind: Deployment
metadata:
  name: veridis-backend
  namespace: veridis-dev

  # Development testing optimization labels
  labels:
    testing.veridis.xyz/testing-level: development
    testing.veridis.xyz/testing-tier: comprehensive
    testing.veridis.xyz/test-profile: developer-enhanced
    testing.veridis.xyz/test-automation: comprehensive
    testing.veridis.xyz/test-coverage: detailed

    # Development testing management labels
    development.veridis.xyz/testing-optimization: developer-focused
    development.veridis.xyz/unit-tests: enabled
    development.veridis.xyz/integration-tests: enabled
    development.veridis.xyz/e2e-tests: enabled
    development.veridis.xyz/performance-tests: enabled

    # Testing development labels
    test.veridis.xyz/testing-level: development
    test.veridis.xyz/test-data-enabled: true
    test.veridis.xyz/test-isolation: enabled
    test.veridis.xyz/test-debugging: comprehensive
    test.veridis.xyz/test-reporting: detailed

  annotations:
    # Development testing optimization annotations
    testing.veridis.xyz/testing-strategy: "developer-productivity-first"
    testing.veridis.xyz/test-optimization: "comprehensive-testing"
    testing.veridis.xyz/coverage-target: "80-percent"
    testing.veridis.xyz/test-automation: "full"
    testing.veridis.xyz/test-reporting: "detailed"

    # Development testing management annotations
    test.veridis.xyz/testing-level: "comprehensive"
    test.veridis.xyz/testing-capabilities: "full"
    test.veridis.xyz/test-debugging: "enabled"
    test.veridis.xyz/test-isolation: "enabled"
    test.veridis.xyz/test-data-management: "automated"

    # Developer productivity annotations
    productivity.veridis.xyz/testing-balance: "productivity-optimized"
    productivity.veridis.xyz/test-feedback: "immediate"
    productivity.veridis.xyz/test-debugging: "comprehensive"
    productivity.veridis.xyz/test-overhead: "minimal"
    productivity.veridis.xyz/developer-experience: "enhanced"

spec:
  template:
    spec:
      containers:
        - name: veridis-backend
          # ==============================================================================
          # Development Testing Environment Variables
          # ==============================================================================
          env:
            # Development testing configuration
            - name: TESTING_ENVIRONMENT
              value: "development"
            - name: TESTING_ENABLED
              value: "true"
            - name: TEST_PROFILE
              value: "comprehensive"
            - name: TESTING_MODE
              value: "development"

            # Unit testing configuration
            - name: UNIT_TESTS_ENABLED
              value: "true"
            - name: UNIT_TEST_PARALLEL
              value: "true"
            - name: UNIT_TEST_THREADS
              value: "4"
            - name: UNIT_TEST_TIMEOUT
              value: "300s"
            - name: UNIT_TEST_VERBOSE
              value: "true"
            - name: UNIT_TEST_NOCAPTURE
              value: "false"
            - name: UNIT_TEST_COVERAGE
              value: "true"

            # Integration testing configuration
            - name: INTEGRATION_TESTS_ENABLED
              value: "true"
            - name: INTEGRATION_TEST_PARALLEL
              value: "true"
            - name: INTEGRATION_TEST_TIMEOUT
              value: "600s"
            - name: INTEGRATION_TEST_DATABASE_RESET
              value: "true"
            - name: INTEGRATION_TEST_CACHE_RESET
              value: "true"
            - name: INTEGRATION_TEST_ISOLATION
              value: "true"

            # End-to-end testing configuration
            - name: E2E_TESTS_ENABLED
              value: "true"
            - name: E2E_TEST_TIMEOUT
              value: "900s"
            - name: E2E_TEST_HEADLESS
              value: "true"
            - name: E2E_TEST_PARALLEL
              value: "false"
            - name: E2E_TEST_SCREENSHOTS
              value: "true"
            - name: E2E_TEST_VIDEO_RECORDING
              value: "true"

            # Performance testing configuration
            - name: PERFORMANCE_TESTS_ENABLED
              value: "true"
            - name: PERF_TEST_DURATION
              value: "60s"
            - name: PERF_TEST_CONNECTIONS
              value: "10"
            - name: PERF_TEST_RPS_TARGET
              value: "100"
            - name: PERF_TEST_LATENCY_TARGET
              value: "100ms"
            - name: PERF_TEST_PROFILING
              value: "true"

            # Load testing configuration (minimal for development)
            - name: LOAD_TESTS_ENABLED
              value: "false"
            - name: LOAD_TEST_DURATION
              value: "30s"
            - name: LOAD_TEST_USERS
              value: "5"
            - name: LOAD_TEST_RAMP_UP
              value: "10s"
            - name: LOAD_TEST_THINK_TIME
              value: "1s"

            # Test coverage configuration
            - name: TEST_COVERAGE_ENABLED
              value: "true"
            - name: TEST_COVERAGE_TARGET
              value: "80"
            - name: TEST_COVERAGE_FORMAT
              value: "html,lcov,json"
            - name: TEST_COVERAGE_OUTPUT_DIR
              value: "/app/coverage"
            - name: TEST_COVERAGE_INCLUDE_TESTS
              value: "false"
            - name: TEST_COVERAGE_EXCLUDE_PATTERNS
              value: "tests/,examples/,target/"

            # Test data management
            - name: TEST_DATA_ENABLED
              value: "true"
            - name: TEST_DATA_RESET_ON_START
              value: "true"
            - name: TEST_DATA_SEED_DATABASE
              value: "true"
            - name: TEST_DATA_CLEAN_ON_EXIT
              value: "true"
            - name: TEST_DATA_ISOLATION
              value: "true"
            - name: TEST_DATA_FIXTURES_DIR
              value: "/app/test-fixtures"

            # Test reporting configuration
            - name: TEST_REPORTING_ENABLED
              value: "true"
            - name: TEST_REPORT_FORMAT
              value: "junit,json,pretty"
            - name: TEST_REPORT_OUTPUT_DIR
              value: "/app/test-reports"
            - name: TEST_REPORT_VERBOSE
              value: "true"
            - name: TEST_REPORT_TIMESTAMPS
              value: "true"
            - name: TEST_REPORT_INCLUDE_PASSED
              value: "true"

            # Test debugging configuration
            - name: TEST_DEBUGGING_ENABLED
              value: "true"
            - name: TEST_DEBUG_LOGGING
              value: "true"
            - name: TEST_DEBUG_BREAKPOINTS
              value: "true"
            - name: TEST_DEBUG_STEP_THROUGH
              value: "true"
            - name: TEST_DEBUG_VARIABLE_INSPECTION
              value: "true"
            - name: TEST_DEBUG_CALL_STACK
              value: "true"

            # Mock services configuration
            - name: MOCK_SERVICES_ENABLED
              value: "true"
            - name: MOCK_EXTERNAL_APIS
              value: "true"
            - name: MOCK_BLOCKCHAIN_CALLS
              value: "true"
            - name: MOCK_DATABASE_CALLS
              value: "false"
            - name: MOCK_CACHE_CALLS
              value: "false"
            - name: MOCK_FILE_SYSTEM
              value: "false"

            # Test environment configuration
            - name: TEST_ENVIRONMENT_ISOLATION
              value: "true"
            - name: TEST_ENVIRONMENT_CLEANUP
              value: "true"
            - name: TEST_ENVIRONMENT_SETUP_TIMEOUT
              value: "60s"
            - name: TEST_ENVIRONMENT_TEARDOWN_TIMEOUT
              value: "30s"
            - name: TEST_ENVIRONMENT_PARALLEL_SETUP
              value: "true"

            # Property-based testing configuration
            - name: PROPERTY_TESTS_ENABLED
              value: "true"
            - name: PROPERTY_TEST_CASES
              value: "100"
            - name: PROPERTY_TEST_SHRINKING
              value: "true"
            - name: PROPERTY_TEST_TIMEOUT
              value: "300s"
            - name: PROPERTY_TEST_SEED
              value: "42"

            # Mutation testing configuration
            - name: MUTATION_TESTS_ENABLED
              value: "false"              # Disabled by default for development
            - name: MUTATION_TEST_TIMEOUT
              value: "600s"
            - name: MUTATION_TEST_THRESHOLD
              value: "80"

            # Benchmark testing configuration
            - name: BENCHMARK_TESTS_ENABLED
              value: "true"
            - name: BENCHMARK_TEST_DURATION
              value: "10s"
            - name: BENCHMARK_TEST_WARMUP
              value: "3s"
            - name: BENCHMARK_TEST_SAMPLES
              value: "100"
            - name: BENCHMARK_TEST_FORMAT
              value: "pretty,json"

            # Security testing configuration
            - name: SECURITY_TESTS_ENABLED
              value: "true"
            - name: SECURITY_TEST_AUDIT
              value: "true"
            - name: SECURITY_TEST_DEPENDENCY_CHECK
              value: "true"
            - name: SECURITY_TEST_SECRETS_SCAN
              value: "true"
            - name: SECURITY_TEST_VULNERABILITY_SCAN
              value: "true"

            # API testing configuration
            - name: API_TESTS_ENABLED
              value: "true"
            - name: API_TEST_CONTRACT_VALIDATION
              value: "true"
            - name: API_TEST_SCHEMA_VALIDATION
              value: "true"
            - name: API_TEST_RESPONSE_VALIDATION
              value: "true"
            - name: API_TEST_PERFORMANCE
              value: "true"

            # Database testing configuration
            - name: DATABASE_TESTS_ENABLED
              value: "true"
            - name: DATABASE_TEST_MIGRATIONS
              value: "true"
            - name: DATABASE_TEST_CONSTRAINTS
              value: "true"
            - name: DATABASE_TEST_PERFORMANCE
              value: "true"
            - name: DATABASE_TEST_ISOLATION
              value: "true"

            # ZK circuit testing configuration
            - name: ZK_TESTS_ENABLED
              value: "true"
            - name: ZK_TEST_CIRCUIT_COMPILATION
              value: "true"
            - name: ZK_TEST_PROOF_GENERATION
              value: "true"
            - name: ZK_TEST_PROOF_VERIFICATION
              value: "true"
            - name: ZK_TEST_PERFORMANCE
              value: "true"
            - name: ZK_TEST_MOCK_PROOFS
              value: "true"           # Use mock proofs for faster testing

            # Compliance testing configuration
            - name: COMPLIANCE_TESTS_ENABLED
              value: "true"
            - name: GDPR_COMPLIANCE_TESTS
              value: "true"
            - name: SOC2_COMPLIANCE_TESTS
              value: "true"
            - name: ISO27001_COMPLIANCE_TESTS
              value: "true"
            - name: AUDIT_TRAIL_TESTS
              value: "true"

            # Bridge testing configuration
            - name: BRIDGE_TESTS_ENABLED
              value: "true"
            - name: BRIDGE_TEST_MOCK_CHAINS
              value: "true"
            - name: BRIDGE_TEST_TRANSACTION_VALIDATION
              value: "true"
            - name: BRIDGE_TEST_STATE_SYNCHRONIZATION
              value: "true"
            - name: BRIDGE_TEST_ERROR_HANDLING
              value: "true"

            # Test execution configuration
            - name: TEST_EXECUTION_STRATEGY
              value: "parallel"
            - name: TEST_EXECUTION_TIMEOUT
              value: "1800s"              # 30 minutes total timeout
            - name: TEST_EXECUTION_RETRY_COUNT
              value: "3"
            - name: TEST_EXECUTION_RETRY_DELAY
              value: "5s"
            - name: TEST_EXECUTION_FAIL_FAST
              value: "false"

            # Test artifact management
            - name: TEST_ARTIFACTS_ENABLED
              value: "true"
            - name: TEST_ARTIFACTS_RETENTION
              value: "7d"
            - name: TEST_ARTIFACTS_COMPRESSION
              value: "true"
            - name: TEST_ARTIFACTS_UPLOAD
              value: "false"              # Disabled for development

            # Continuous testing configuration
            - name: CONTINUOUS_TESTING_ENABLED
              value: "true"
            - name: TEST_ON_FILE_CHANGE
              value: "true"
            - name: TEST_CHANGE_DETECTION
              value: "true"
            - name: TEST_SMART_EXECUTION
              value: "true"
            - name: TEST_INCREMENTAL_EXECUTION
              value: "true"

          # ==============================================================================
          # Development Testing Volume Mounts
          # ==============================================================================
          volumeMounts:
            # Test configuration volume
            - name: test-config
              mountPath: /app/test-config
              readOnly: true

            # Test data fixtures volume
            - name: test-fixtures
              mountPath: /app/test-fixtures
              readOnly: true

            # Test reports volume
            - name: test-reports
              mountPath: /app/test-reports
              readOnly: false

            # Test coverage volume
            - name: test-coverage
              mountPath: /app/coverage
              readOnly: false

            # Test artifacts volume
            - name: test-artifacts
              mountPath: /app/test-artifacts
              readOnly: false

            # Test database volume
            - name: test-database
              mountPath: /app/test-db
              readOnly: false

            # Test cache volume
            - name: test-cache
              mountPath: /app/test-cache
              readOnly: false

            # Test logs volume
            - name: test-logs
              mountPath: /app/test-logs
              readOnly: false

            # Test screenshots volume (for E2E tests)
            - name: test-screenshots
              mountPath: /app/test-screenshots
              readOnly: false

            # Test videos volume (for E2E tests)
            - name: test-videos
              mountPath: /app/test-videos
              readOnly: false

          # ==============================================================================
          # Development Testing Ports
          # ==============================================================================
          ports:
            # Main application port
            - name: http
              containerPort: 8080
              protocol: TCP

            # Test runner API port
            - name: test-api
              containerPort: 8090
              protocol: TCP

            # Test debugging port
            - name: test-debug
              containerPort: 8091
              protocol: TCP

            # Test metrics port
            - name: test-metrics
              containerPort: 8092
              protocol: TCP

            # Test coverage server port
            - name: test-coverage
              containerPort: 8093
              protocol: TCP

            # Mock services port
            - name: mock-services
              containerPort: 8094
              protocol: TCP

          # ==============================================================================
          # Development Testing Command Override
          # ==============================================================================
          command:
            - /bin/sh
            - -c
            - |
              echo "Starting Veridis Backend with Testing Configuration..."

              # Create test directories
              mkdir -p /app/test-reports
              mkdir -p /app/coverage
              mkdir -p /app/test-artifacts
              mkdir -p /app/test-logs
              mkdir -p /app/test-screenshots
              mkdir -p /app/test-videos

              # Set permissions
              chmod -R 755 /app/test-*
              chmod -R 755 /app/coverage

              # Initialize test environment
              if [ "$TEST_DATA_ENABLED" = "true" ]; then
                echo "Initializing test data..."
                /app/scripts/init-test-data.sh
              fi

              # Start the application
              exec /app/veridis_backend --config /app/config/development.toml

        # ==============================================================================
        # Test Runner Sidecar Container
        # ==============================================================================
        - name: test-runner
          image: veridis/test-runner:v3.2.1-dev

          # ==============================================================================
          # Test Runner Environment Variables
          # ==============================================================================
          env:
            # Test runner configuration
            - name: TEST_RUNNER_MODE
              value: "development"
            - name: MAIN_SERVICE_HOST
              value: "localhost"
            - name: MAIN_SERVICE_PORT
              value: "8080"

            # Test execution configuration
            - name: TEST_EXECUTION_ENGINE
              value: "cargo-test"
            - name: TEST_PARALLEL_EXECUTION
              value: "true"
            - name: TEST_MAX_THREADS
              value: "4"
            - name: TEST_TIMEOUT
              value: "600s"

            # Test discovery configuration
            - name: TEST_DISCOVERY_PATTERNS
              value: "tests/**/*.rs,benches/**/*.rs"
            - name: TEST_EXCLUDE_PATTERNS
              value: "target/**,node_modules/**"
            - name: TEST_AUTO_DISCOVERY
              value: "true"

            # Test reporting configuration
            - name: TEST_REPORTER_ENABLED
              value: "true"
            - name: TEST_REPORT_FORMATS
              value: "junit,json,html"
            - name: TEST_REPORT_UPLOAD
              value: "false"

            # Coverage analysis configuration
            - name: COVERAGE_ANALYSIS_ENABLED
              value: "true"
            - name: COVERAGE_TOOL
              value: "tarpaulin"
            - name: COVERAGE_THRESHOLD
              value: "80"
            - name: COVERAGE_FAIL_ON_THRESHOLD
              value: "false"

            # Mock services configuration
            - name: MOCK_SERVER_ENABLED
              value: "true"
            - name: MOCK_SERVER_PORT
              value: "8094"
            - name: MOCK_EXTERNAL_SERVICES
              value: "true"

            # Test data management
            - name: TEST_DATA_MANAGER_ENABLED
              value: "true"
            - name: TEST_DATA_CLEANUP_STRATEGY
              value: "after-each"
            - name: TEST_DATA_ISOLATION_STRATEGY
              value: "database-transaction"

            # Continuous testing configuration
            - name: WATCH_MODE_ENABLED
              value: "true"
            - name: WATCH_PATTERNS
              value: "src/**/*.rs,tests/**/*.rs"
            - name: WATCH_DEBOUNCE_MS
              value: "500"

            # Performance testing configuration
            - name: PERFORMANCE_TESTING_ENABLED
              value: "true"
            - name: BENCHMARK_RUNNER
              value: "criterion"
            - name: LOAD_TESTING_TOOL
              value: "custom"

          # ==============================================================================
          # Test Runner Volume Mounts
          # ==============================================================================
          volumeMounts:
            # Shared test configuration
            - name: test-config
              mountPath: /test/config
              readOnly: true

            # Shared test fixtures
            - name: test-fixtures
              mountPath: /test/fixtures
              readOnly: true

            # Shared test reports
            - name: test-reports
              mountPath: /test/reports
              readOnly: false

            # Shared test coverage
            - name: test-coverage
              mountPath: /test/coverage
              readOnly: false

            # Shared test artifacts
            - name: test-artifacts
              mountPath: /test/artifacts
              readOnly: false

            # Source code volume (for test discovery)
            - name: source-code
              mountPath: /app/src
              readOnly: true

            # Test runner data
            - name: test-runner-data
              mountPath: /test/data
              readOnly: false

          # ==============================================================================
          # Test Runner Ports
          # ==============================================================================
          ports:
            # Test runner API
            - name: test-api
              containerPort: 9000
              protocol: TCP

            # Test results server
            - name: test-results
              containerPort: 9001
              protocol: TCP

            # Coverage server
            - name: coverage-server
              containerPort: 9002
              protocol: TCP

            # Mock services
            - name: mock-server
              containerPort: 8094
              protocol: TCP

          # ==============================================================================
          # Test Runner Resources
          # ==============================================================================
          resources:
            requests:
              cpu: "500m"
              memory: "1Gi"
            limits:
              cpu: "1000m"
              memory: "2Gi"

          # ==============================================================================
          # Test Runner Health Checks
          # ==============================================================================
          livenessProbe:
            httpGet:
              path: /health
              port: test-api
            initialDelaySeconds: 30
            periodSeconds: 30
            timeoutSeconds: 5
            failureThreshold: 3

          readinessProbe:
            httpGet:
              path: /ready
              port: test-api
            initialDelaySeconds: 10
            periodSeconds: 10
            timeoutSeconds: 3
            failureThreshold: 3

      # ==============================================================================
      # Development Testing Volumes
      # ==============================================================================
      volumes:
        # Test configuration volume
        - name: test-config
          configMap:
            name: veridis-development-test-config
            defaultMode: 0644

        # Test fixtures volume
        - name: test-fixtures
          configMap:
            name: veridis-development-test-fixtures
            defaultMode: 0644

        # Test reports volume
        - name: test-reports
          emptyDir:
            sizeLimit: "1Gi"
            medium: ""

        # Test coverage volume
        - name: test-coverage
          emptyDir:
            sizeLimit: "500Mi"
            medium: ""

        # Test artifacts volume
        - name: test-artifacts
          emptyDir:
            sizeLimit: "2Gi"
            medium: ""

        # Test database volume
        - name: test-database
          emptyDir:
            sizeLimit: "1Gi"
            medium: ""

        # Test cache volume
        - name: test-cache
          emptyDir:
            sizeLimit: "200Mi"
            medium: ""

        # Test logs volume
        - name: test-logs
          emptyDir:
            sizeLimit: "500Mi"
            medium: ""

        # Test screenshots volume
        - name: test-screenshots
          emptyDir:
            sizeLimit: "200Mi"
            medium: ""

        # Test videos volume
        - name: test-videos
          emptyDir:
            sizeLimit: "1Gi"
            medium: ""

        # Source code volume (for test runner)
        - name: source-code
          emptyDir:
            sizeLimit: "1Gi"
            medium: ""

        # Test runner data volume
        - name: test-runner-data
          emptyDir:
            sizeLimit: "500Mi"
            medium: ""

---
# ==============================================================================
# Development Test Configuration ConfigMap
# ==============================================================================
apiVersion: v1
kind: ConfigMap
metadata:
  name: veridis-development-test-config
  namespace: veridis-dev

  labels:
    testing.veridis.xyz/component: test-config
    testing.veridis.xyz/environment: development
    app.kubernetes.io/name: test-config
    app.kubernetes.io/component: config
    app.kubernetes.io/part-of: veridis-protocol

  annotations:
    testing.veridis.xyz/description: "Development testing configuration for Veridis Protocol"
    testing.veridis.xyz/config-version: "development-v1"
    testing.veridis.xyz/optimization-level: "comprehensive"

data:
  # Cargo test configuration
  cargo-test.toml: |
    # Cargo test configuration for development

    [test]
    # Test execution settings
    timeout = 600
    parallel = true
    nocapture = false
    color = "auto"

    # Test discovery
    test-threads = 4

    # Environment variables for tests
    [test.env]
    RUST_LOG = "debug"
    RUST_BACKTRACE = "1"
    TEST_ENVIRONMENT = "development"

    [profile.test]
    # Test build optimizations
    opt-level = 0
    debug = true
    debug-assertions = true
    overflow-checks = true
    lto = false
    panic = "unwind"
    incremental = true
    codegen-units = 256

  # Test coverage configuration
  tarpaulin.toml: |
    [tool.tarpaulin.coverage]
    # Coverage configuration
    exclude-files = [
        "tests/*",
        "examples/*",
        "benches/*",
        "*/tests.rs",
        "*/test_*.rs"
    ]

    # Output formats
    out = ["Html", "Lcov", "Json"]
    output-dir = "coverage"

    # Coverage thresholds
    fail-under = 80
    ignore-panics = true
    count = true

    # Include/exclude patterns
    include-tests = false
    post-test = true
    follow-exec = true

    [tool.tarpaulin.report]
    # Report generation
    skip-clean = false
    target-dir = "target/tarpaulin"
    workspace = true
    verbose = true
    debug = true
    dump-traces = true

  # Property-based test configuration
  proptest.toml: |
    # Proptest configuration
    cases = 100
    max_shrink_iters = 1000
    max_shrink_time = 10000

    # Test case generation
    source_file = "proptest-regressions"
    fork = false
    timeout = 5000
    max_global_rejects = 65536

    # Failure persistence
    failure_persistence = "FailurePersistence::SourceParallel"

    # Verbose output for development
    verbose = 1

  # Criterion benchmark configuration
  criterion.toml: |
    # Criterion benchmark configuration

    [measurement]
    # Measurement settings
    measurement_time = 10
    warm_up_time = 3
    sample_size = 100

    [plotting]
    # Plot generation (disabled for development)
    create_dir = false

    [output]
    # Output configuration
    verbose = true
    quiet = false

    [profiling]
    # Profiling integration
    enabled = true
    profiler = "perf"

  # Jest configuration for ZK tests
  jest.config.js: |
    module.exports = {
      // Jest configuration for ZK circuit tests
      preset: 'ts-jest',
      testEnvironment: 'node',

      // Test files
      testMatch: [
        '**/tests/**/*.test.(ts|js)',
        '**/src/**/__tests__/**/*.(ts|js)',
        '**/src/**/?(*.)(spec|test).(ts|js)'
      ],

      // Coverage configuration
      collectCoverage: true,
      coverageDirectory: 'coverage',
      coverageReporters: ['html', 'lcov', 'json', 'text'],
      coverageThreshold: {
        global: {
          branches: 70,
          functions: 70,
          lines: 70,
          statements: 70
        }
      },

      // Test setup
      setupFilesAfterEnv: ['<rootDir>/tests/setup.ts'],

      // Module resolution
      moduleFileExtensions: ['ts', 'tsx', 'js', 'jsx', 'json'],
      transform: {
        '^.+\\.(ts|tsx)$': 'ts-jest'
      },

      // Test timeout
      testTimeout: 30000,

      // Verbose output for development
      verbose: true,

      // Watch mode (for development)
      watchman: true,
      watchPathIgnorePatterns: ['node_modules', 'build', 'dist']
    };

  # Test database configuration
  test-database.toml: |
    # Test database configuration

    [database]
    # Connection settings
    host = "localhost"
    port = 5432
    database = "veridis_test"
    username = "veridis_test"
    password = "test_password"

    # Pool settings
    max_connections = 5
    min_connections = 1
    connection_timeout = 30
    idle_timeout = 300

    # Test-specific settings
    reset_on_startup = true
    seed_data = true
    isolation_level = "ReadCommitted"

    [migrations]
    # Migration settings
    auto_migrate = true
    migration_dir = "migrations"
    rollback_on_failure = true

  # API test configuration
  api-test.json: |
    {
      "apiTesting": {
        "baseUrl": "http://localhost:8080",
        "timeout": 30000,
        "retries": 3,
        "headers": {
          "Content-Type": "application/json",
          "Accept": "application/json"
        }
      },
      "validation": {
        "schemaValidation": true,
        "responseValidation": true,
        "contractValidation": true
      },
      "reporting": {
        "format": ["json", "html"],
        "outputDir": "test-reports/api",
        "includeRequestResponse": true
      },
      "performance": {
        "enabled": true,
        "thresholds": {
          "responseTime": 1000,
          "availability": 99
        }
      }
    }

  # E2E test configuration
  e2e-test.json: |
    {
      "e2eTesting": {
        "browser": "chromium",
        "headless": true,
        "viewport": {
          "width": 1280,
          "height": 720
        },
        "timeout": 30000
      },
      "screenshots": {
        "enabled": true,
        "onFailure": true,
        "directory": "test-screenshots"
      },
      "video": {
        "enabled": true,
        "directory": "test-videos",
        "quality": "medium"
      },
      "reporting": {
        "format": ["json", "html"],
        "outputDir": "test-reports/e2e"
      }
    }

---
# ==============================================================================
# Development Test Fixtures ConfigMap
# ==============================================================================
apiVersion: v1
kind: ConfigMap
metadata:
  name: veridis-development-test-fixtures
  namespace: veridis-dev

  labels:
    testing.veridis.xyz/component: test-fixtures
    testing.veridis.xyz/environment: development
    app.kubernetes.io/name: test-fixtures
    app.kubernetes.io/component: fixtures
    app.kubernetes.io/part-of: veridis-protocol

data:
  # User test fixtures
  users.json: |
    {
      "test_users": [
        {
          "id": "test-user-1",
          "email": "testuser1@example.com",
          "wallet_address": "0x1234567890abcdef1234567890abcdef12345678",
          "starknet_address": "0x0123456789abcdef0123456789abcdef01234567",
          "created_at": "2024-01-01T00:00:00Z",
          "verified": true
        },
        {
          "id": "test-user-2",
          "email": "testuser2@example.com",
          "wallet_address": "0xabcdef1234567890abcdef1234567890abcdef12",
          "starknet_address": "0x89abcdef0123456789abcdef0123456789abcdef",
          "created_at": "2024-01-02T00:00:00Z",
          "verified": false
        }
      ]
    }

  # Identity test fixtures
  identities.json: |
    {
      "test_identities": [
        {
          "id": "identity-1",
          "user_id": "test-user-1",
          "did": "did:veridis:starknet:0x0123456789abcdef0123456789abcdef01234567",
          "public_key": "0x1234567890abcdef1234567890abcdef1234567890abcdef1234567890abcdef",
          "metadata": {
            "name": "Test Identity 1",
            "description": "Test identity for unit tests"
          },
          "created_at": "2024-01-01T00:00:00Z"
        }
      ]
    }

  # Attestation test fixtures
  attestations.json: |
    {
      "test_attestations": [
        {
          "id": "attestation-1",
          "identity_id": "identity-1",
          "attestation_type": "email_verification",
          "attestation_data": {
            "email": "testuser1@example.com",
            "verified_at": "2024-01-01T00:00:00Z"
          },
          "proof": "0xabcdef1234567890abcdef1234567890abcdef1234567890abcdef1234567890",
          "status": "verified",
          "created_at": "2024-01-01T00:00:00Z"
        }
      ]
    }

  # ZK circuit test fixtures
  zk-circuits.json: |
    {
      "test_circuits": [
        {
          "id": "circuit-1",
          "name": "email_verification",
          "circuit_file": "email_verification.json",
          "witness_generator": "email_witness.js",
          "proving_key": "email_pk.key",
          "verification_key": "email_vk.key",
          "constraints": 1000,
          "mock_proof": true
        }
      ]
    }

  # Test database seed data
  seed-data.sql: |
    -- Test database seed data
    INSERT INTO users (id, email, wallet_address, starknet_address, created_at, verified)
    VALUES
      ('test-user-1', 'testuser1@example.com', '0x1234567890abcdef1234567890abcdef12345678', '0x0123456789abcdef0123456789abcdef01234567', '2024-01-01 00:00:00', true),
      ('test-user-2', 'testuser2@example.com', '0xabcdef1234567890abcdef1234567890abcdef12', '0x89abcdef0123456789abcdef0123456789abcdef', '2024-01-02 00:00:00', false);

    INSERT INTO identities (id, user_id, did, public_key, metadata, created_at)
    VALUES
      ('identity-1', 'test-user-1', 'did:veridis:starknet:0x0123456789abcdef0123456789abcdef01234567', '0x1234567890abcdef1234567890abcdef1234567890abcdef1234567890abcdef', '{"name": "Test Identity 1", "description": "Test identity for unit tests"}', '2024-01-01 00:00:00');

    INSERT INTO attestations (id, identity_id, attestation_type, attestation_data, proof, status, created_at)
    VALUES
      ('attestation-1', 'identity-1', 'email_verification', '{"email": "testuser1@example.com", "verified_at": "2024-01-01T00:00:00Z"}', '0xabcdef1234567890abcdef1234567890abcdef1234567890abcdef1234567890', 'verified', '2024-01-01 00:00:00');

---
# ==============================================================================
# Development Test Runner Job
# ==============================================================================
apiVersion: batch/v1
kind: Job
metadata:
  name: veridis-development-test-suite
  namespace: veridis-dev

  labels:
    testing.veridis.xyz/component: test-suite
    testing.veridis.xyz/environment: development
    app.kubernetes.io/name: test-suite
    app.kubernetes.io/component: testing
    app.kubernetes.io/part-of: veridis-protocol

  annotations:
    testing.veridis.xyz/description: "Development test suite execution job"
    testing.veridis.xyz/test-types: "unit,integration,e2e,performance"
    testing.veridis.xyz/coverage-target: "80%"

spec:
  backoffLimit: 3
  completions: 1
  parallelism: 1

  template:
    metadata:
      labels:
        testing.veridis.xyz/component: test-suite
        app.kubernetes.io/name: test-suite

    spec:
      restartPolicy: Never

      containers:
        - name: test-runner
          image: veridis/test-runner:v3.2.1-dev

          command:
            - /bin/bash
            - -c
            - |
              echo "Starting Veridis Development Test Suite..."

              # Create output directories
              mkdir -p /test/reports/{unit,integration,e2e,performance}
              mkdir -p /test/coverage
              mkdir -p /test/artifacts

              # Set permissions
              chmod -R 755 /test

              # Wait for main service to be ready
              echo "Waiting for Veridis Backend to be ready..."
              while ! curl -f http://veridis-backend-service.veridis-dev.svc.cluster.local:8080/health; do
                sleep 5
              done

              # Run unit tests
              echo "Running unit tests..."
              cargo test --lib --bins --tests \
                --manifest-path /app/Cargo.toml \
                --target-dir /test/target \
                --test-threads 4 \
                --timeout 300 \
                -- --nocapture \
                2>&1 | tee /test/reports/unit/unit-tests.log

              # Run integration tests
              echo "Running integration tests..."
              cargo test --test '*' \
                --manifest-path /app/Cargo.toml \
                --target-dir /test/target \
                --test-threads 2 \
                --timeout 600 \
                -- --nocapture \
                2>&1 | tee /test/reports/integration/integration-tests.log

              # Generate test coverage
              echo "Generating test coverage..."
              cargo tarpaulin \
                --manifest-path /app/Cargo.toml \
                --target-dir /test/target \
                --out Html --out Lcov --out Json \
                --output-dir /test/coverage \
                --timeout 600 \
                --verbose \
                2>&1 | tee /test/reports/coverage.log

              # Run benchmarks
              if [ "$BENCHMARK_TESTS_ENABLED" = "true" ]; then
                echo "Running benchmark tests..."
                cargo bench \
                  --manifest-path /app/Cargo.toml \
                  --target-dir /test/target \
                  2>&1 | tee /test/reports/performance/benchmarks.log
              fi

              # Run security audit
              if [ "$SECURITY_TESTS_ENABLED" = "true" ]; then
                echo "Running security audit..."
                cargo audit 2>&1 | tee /test/reports/security-audit.log
              fi

              # Run API tests
              if [ "$API_TESTS_ENABLED" = "true" ]; then
                echo "Running API tests..."
                # Add API testing logic here
                echo "API tests completed" | tee /test/reports/api-tests.log
              fi

              # Generate test summary
              echo "Generating test summary..."
              cat > /test/reports/test-summary.json << EOF
              {
                "timestamp": "$(date -u +%Y-%m-%dT%H:%M:%SZ)",
                "environment": "development",
                "test_types": ["unit", "integration", "performance", "security"],
                "coverage_threshold": 80,
                "status": "completed"
              }
              EOF

              echo "Test suite execution completed!"

          env:
            # Test configuration
            - name: RUST_LOG
              value: "debug"
            - name: RUST_BACKTRACE
              value: "1"
            - name: TEST_ENVIRONMENT
              value: "development"
            - name: CARGO_TARGET_DIR
              value: "/test/target"

            # Test feature flags
            - name: UNIT_TESTS_ENABLED
              value: "true"
            - name: INTEGRATION_TESTS_ENABLED
              value: "true"
            - name: E2E_TESTS_ENABLED
              value: "true"
            - name: PERFORMANCE_TESTS_ENABLED
              value: "true"
            - name: SECURITY_TESTS_ENABLED
              value: "true"
            - name: API_TESTS_ENABLED
              value: "true"
            - name: BENCHMARK_TESTS_ENABLED
              value: "true"

          volumeMounts:
            # Source code
            - name: source-code
              mountPath: /app
              readOnly: true

            # Test outputs
            - name: test-outputs
              mountPath: /test
              readOnly: false

            # Test configuration
            - name: test-config
              mountPath: /test/config
              readOnly: true

          resources:
            requests:
              cpu: "1000m"
              memory: "2Gi"
            limits:
              cpu: "2000m"
              memory: "4Gi"

      volumes:
        # Source code volume
        - name: source-code
          emptyDir:
            sizeLimit: "1Gi"

        # Test outputs volume
        - name: test-outputs
          emptyDir:
            sizeLimit: "5Gi"

        # Test configuration
        - name: test-config
          configMap:
            name: veridis-development-test-config

---
# ==============================================================================
# Development Test Results Service
# ==============================================================================
apiVersion: v1
kind: Service
metadata:
  name: veridis-test-results-service
  namespace: veridis-dev

  labels:
    testing.veridis.xyz/component: test-results
    testing.veridis.xyz/environment: development
    app.kubernetes.io/name: test-results
    app.kubernetes.io/component: service
    app.kubernetes.io/part-of: veridis-protocol

  annotations:
    testing.veridis.xyz/description: "Development test results service"
    testing.veridis.xyz/service-type: "test-reporting"

spec:
  type: ClusterIP
  selector:
    app.kubernetes.io/name: veridis
    app.kubernetes.io/component: backend

  ports:
    # Test API port
    - name: test-api
      port: 8090
      targetPort: test-api
      protocol: TCP

    # Test debugging port
    - name: test-debug
      port: 8091
      targetPort: test-debug
      protocol: TCP

    # Test metrics port
    - name: test-metrics
      port: 8092
      targetPort: test-metrics
      protocol: TCP

    # Test coverage server port
    - name: test-coverage
      port: 8093
      targetPort: test-coverage
      protocol: TCP

---
# ==============================================================================
# Development Test Monitoring ServiceMonitor
# ==============================================================================
apiVersion: monitoring.coreos.com/v1
kind: ServiceMonitor
metadata:
  name: veridis-dev-test-monitor
  namespace: veridis-dev

  labels:
    testing.veridis.xyz/component: test-monitoring
    testing.veridis.xyz/environment: development
    monitoring.veridis.xyz/service: testing
    app.kubernetes.io/name: test-monitoring
    app.kubernetes.io/component: monitoring
    app.kubernetes.io/part-of: veridis-protocol

spec:
  selector:
    matchLabels:
      app.kubernetes.io/name: veridis
      app.kubernetes.io/component: backend
      testing.veridis.xyz/environment: development

  endpoints:
    - port: test-metrics
      interval: 30s
      path: /test-metrics
      scheme: http
      scrapeTimeout: 10s

      metricRelabelings:
        - sourceLabels: [__name__]
          targetLabel: environment
          replacement: development

        - sourceLabels: [__name__]
          targetLabel: service
          replacement: testing

# ==============================================================================
# Veridis Development Testing Summary and Enterprise Architecture
# ==============================================================================
#
# COMPREHENSIVE VERIDIS DEVELOPMENT TESTING STRATEGY:
# ===================================================
#
# VERIDIS DEVELOPMENT TESTING ARCHITECTURE OVERVIEW:
# --------------------------------------------------
# 1. Comprehensive Testing Framework Integration:
#    - Comprehensive enterprise-grade development testing with intelligent testing management and advanced developer-focused optimization
#    - Advanced testing configuration with comprehensive developer productivity, debugging support, coverage efficiency, and comprehensive operational excellence
#    - Multi-tier testing architecture with unit testing, integration testing, E2E testing, and comprehensive testing intelligence
#    - Enterprise testing policies with developer-friendly enforcement, productivity controls, testing automation, and comprehensive testing procedures
#    - Performance optimization with intelligent testing allocation, developer efficiency, testing acceleration, and productivity for maximum development performance
#
# 2. Advanced Test Execution and Automation:
#    - Developer-focused test execution with automation optimization, debugging efficiency, coverage tracking, and comprehensive productivity coordination
#    - Advanced testing configuration with test tools, debugging features, coverage frameworks, and comprehensive testing intelligence
#    - Flexible testing optimization with developer workflow, productivity enhancement, and comprehensive testing intelligence
#    - Testing intelligence with test procedures, debugging support, testing automation, and comprehensive testing coordination
#    - Development excellence with testing optimization, productivity workflows, testing automation, and comprehensive testing environment management
#
# 3. Test Coverage and Quality Assurance:
#    - Coverage-optimized testing with comprehensive analysis, quality tracking, performance monitoring, and comprehensive coverage coordination
#    - Advanced coverage configuration with coverage tools, quality metrics, testing validation, and comprehensive coverage intelligence
#    - Flexible quality optimization with testing standards, coverage enhancement, and comprehensive quality intelligence
#    - Quality intelligence with coverage procedures, testing support, quality automation, and comprehensive quality coordination
#    - Testing excellence with coverage optimization, quality workflows, testing automation, and comprehensive quality environment management
#
# ENTERPRISE DEVELOPMENT TESTING FEATURES:
# ========================================
# Advanced Testing Management and Developer Productivity:
#   - Multi-tier testing architecture with developer optimization, debugging testing, coverage integration, and comprehensive testing configurations
#   - Intelligent testing management with developer optimization, debugging-focused allocation, productivity enhancement, and comprehensive testing decisions
#   - Testing discovery with developer optimization, debugging management, testing policies, and comprehensive testing analytics
#   - Performance management with developer productivity, debugging efficiency, testing optimization, and comprehensive performance intelligence
#   - Testing processing tuning with debugging management, productivity optimization, performance algorithms, and intelligent testing optimization
#
# This Development Testing configuration provides enterprise-grade developer productivity enhancement with comprehensive testing support, intelligent debugging optimization, advanced coverage features, and operational excellence while maintaining appropriate performance, efficiency validation, and comprehensive testing for the Veridis decentralized identity protocol development ecosystem!
#
# ==============================================================================
